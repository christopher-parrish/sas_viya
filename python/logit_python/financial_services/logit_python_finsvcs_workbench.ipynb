{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "### Create Dataframe ###\n",
    "########################\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "dm_inputdf = pd.read_csv(\"/workspaces/workspace/data/financial_services_prep.csv\", header=0)\n",
    "print(dm_inputdf.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "### Model Parameters ###\n",
    "########################\n",
    "\n",
    "### import python libraries\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "### model manager information\n",
    "model_name = 'logit_python_finsvcs'\n",
    "project_name = 'Financial Services'\n",
    "description = 'Logistic Regression'\n",
    "model_type = 'logistic_regression'\n",
    "predict_syntax = 'predict_proba'\n",
    "\n",
    "### define macro variables for model\n",
    "dm_dec_target = 'event_indicator'\n",
    "dm_partitionvar = 'analytic_partition'\n",
    "create_new_partition = 'no' # 'yes', 'no'\n",
    "dm_key = 'account_id' \n",
    "dm_classtarget_level = ['0', '1']\n",
    "dm_partition_validate_val, dm_partition_train_val, dm_partition_test_val = [0, 1, 2]\n",
    "dm_partition_validate_perc, dm_partition_train_perc, dm_partition_test_perc = [0.3, 0.6, 0.1]\n",
    "\n",
    "### create list of regressors\n",
    "keep_predictors = [\n",
    "    'net_worth',\n",
    "    'credit_score',\n",
    "    'num_dependents',\n",
    "    'at_current_job_1_year',\n",
    "    'credit_history_mos',\n",
    "    'job_in_education',\n",
    "    'num_transactions',\n",
    "    'debt_to_income',\n",
    "    'amount',\n",
    "    'gender',\n",
    "    'age',\n",
    "    'job_in_hospitality'\n",
    "    ]\n",
    "#rejected_predictors = []\n",
    "\n",
    "### mlflow\n",
    "use_mlflow = 'no' # 'yes', 'no'\n",
    "mlflow_run_to_use = 0\n",
    "mlflow_class_labels =['TENSOR']\n",
    "mlflow_predict_syntax = 'predict'\n",
    "\n",
    "### var to consider in bias assessment\n",
    "bias_var = 'gender'\n",
    "\n",
    "### var to consider in partial dependency\n",
    "pd_var1 = 'credit_score'\n",
    "pd_var2 = 'net_worth'\n",
    "\n",
    "### create partition column, if not already in dataset\n",
    "if create_new_partition == 'yes':\n",
    "    dm_inputdf = shuffle(dm_inputdf)\n",
    "    dm_inputdf.reset_index(inplace=True, drop=True)\n",
    "    validate_rows = round(len(dm_inputdf)*dm_partition_validate_perc)\n",
    "    train_rows = round(len(dm_inputdf)*dm_partition_train_perc) + validate_rows\n",
    "    test_rows = len(dm_inputdf)-train_rows\n",
    "    dm_inputdf.loc[0:validate_rows,dm_partitionvar] = dm_partition_validate_val\n",
    "    dm_inputdf.loc[validate_rows:train_rows,dm_partitionvar] = dm_partition_train_val\n",
    "    dm_inputdf.loc[train_rows:,dm_partitionvar] = dm_partition_test_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "### Final Modeling Columns ###\n",
    "##############################\n",
    "\n",
    "### create list of model variables\n",
    "dm_input = list(dm_inputdf.columns.values)\n",
    "macro_vars = (dm_dec_target + ' ' + dm_partitionvar + ' ' + dm_key).split()\n",
    "rejected_predictors = [i for i in dm_input if i not in keep_predictors]\n",
    "rejected_vars = rejected_predictors # + macro_vars (include macro_vars if rejected_predictors are explicitly listed - not contra keep_predictors)\n",
    "for i in rejected_vars:\n",
    "    dm_input.remove(i)\n",
    "print(dm_input)\n",
    "\n",
    "### create prediction variables\n",
    "dm_predictionvar = [str('P_') + dm_dec_target + dm_classtarget_level[0], str('P_') + dm_dec_target + dm_classtarget_level[1]]\n",
    "dm_classtarget_intovar = str('I_') + dm_dec_target\n",
    "\n",
    "##################\n",
    "### Data Split ###\n",
    "##################\n",
    "\n",
    "### create train, test, validate datasets using existing partition column\n",
    "dm_traindf = dm_inputdf[dm_inputdf[dm_partitionvar] == dm_partition_train_val]\n",
    "X_train = dm_traindf.loc[:, dm_input]\n",
    "y_train = dm_traindf[dm_dec_target]\n",
    "dm_testdf = dm_inputdf.loc[(dm_inputdf[dm_partitionvar] == dm_partition_test_val)]\n",
    "X_test = dm_testdf.loc[:, dm_input]\n",
    "y_test = dm_testdf[dm_dec_target]\n",
    "dm_validdf = dm_inputdf.loc[(dm_inputdf[dm_partitionvar] == dm_partition_validate_val)]\n",
    "X_valid = dm_validdf.loc[:, dm_input]\n",
    "y_valid = dm_validdf[dm_dec_target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "### Training Code ###\n",
    "#####################\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "### estimate & fit model\n",
    "dm_model = LogisticRegression(\n",
    "        tol=1e-8,\n",
    "        fit_intercept=True,\n",
    "        solver='newton-cg',\n",
    "        verbose=0,\n",
    "        max_iter=None\n",
    "    )\n",
    "dm_model.fit(X_train, y_train)\n",
    "\n",
    "print('score_train:', dm_model.score(X_train, y_train))\n",
    "print('score_test:', dm_model.score(X_test, y_test))\n",
    "print('score_valid:', dm_model.score(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "### Pickle Model ###\n",
    "####################\n",
    "\n",
    "import pickle\n",
    "\n",
    "dm_pklpath = \"/workspaces/workspace/data/financial_services.pkl\"\n",
    "\n",
    "with open(dm_pklpath, 'wb') as f:\n",
    "\tpickle.dump(dm_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "### SAS API ###\n",
    "###############\n",
    "\n",
    "from sasviya.ml.linear_model import LogisticRegression\n",
    "\n",
    "### estimate & fit model\n",
    "dm_model = LogisticRegression(\n",
    "        tol=1e-8,\n",
    "        fit_intercept=True,\n",
    "        solver=\"newrap\",\n",
    "        selection=None,\n",
    "        verbose=0,\n",
    "        max_iter=None,\n",
    "        max_time=None\n",
    "        )\n",
    "dm_model.fit(X_train, y_train)\n",
    "\n",
    "print('score_train:', dm_model.score(X_train, y_train))\n",
    "print('score_test:', dm_model.score(X_test, y_test))\n",
    "print('score_valid:', dm_model.score(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "### Save Model as Astore File ###\n",
    "#################################\n",
    "\n",
    "dm_model.export(file=\"/workspaces/workspace/data/financial_services.astore\", replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "### Save Model in Table ###\n",
    "###########################\n",
    "\n",
    "dm_model.save(\"/workspaces/workspace/data/financial_services.model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Workbench Python",
   "language": "python",
   "name": "workbench_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
